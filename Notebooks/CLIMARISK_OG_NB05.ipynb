{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb05_title"
      },
      "source": [
        "# Notebook 05 -- Batch Pipeline: Pre-calculo CLIMADA para Railway\n",
        "\n",
        "**CLIMARISK-OG** | Petrobras | TRL5  \n",
        "Ativo: REDUC -- Refinaria Duque de Caxias, RJ  \n",
        "\n",
        "Este notebook consolida a logica dos NB01-NB04 em um **pipeline unico**\n",
        "que executa todas as analises de risco climatico em sequencia e exporta\n",
        "os resultados em formato JSON padronizado.\n",
        "\n",
        "**Objetivo**: demonstrar que o motor CLIMADA pode rodar como batch job\n",
        "automatizado no Railway, sem intervencao manual.\n",
        "\n",
        "**Evidencia TRL5**: script de producao funcional, reprodutivel e auditavel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nb05_install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77547ec-4c33-4a6b-f439-3313911798c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.1/780.1 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.9/151.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.5/91.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 4.0.0 requires dill<0.3.9,>=0.3.0, but you have dill 0.4.1 which is incompatible.\n",
            "datasets 4.0.0 requires multiprocess<0.70.17, but you have multiprocess 0.70.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install climada climada-petals boto3 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nb05_bloco01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f5689f-dc41-4393-9399-d7d19554fec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "CLIMADA versao: 6.1.0\n",
            "boto3: disponivel\n",
            "\n",
            "OK - Ambiente verificado\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 1: VERIFICACAO DE AMBIENTE\n",
        "# =============================================================================\n",
        "import sys\n",
        "print(f\"Python: {sys.version}\")\n",
        "\n",
        "import climada\n",
        "try:\n",
        "    ver = climada.__version__\n",
        "except AttributeError:\n",
        "    from importlib.metadata import version\n",
        "    ver = version(\"climada\")\n",
        "print(f\"CLIMADA versao: {ver}\")\n",
        "\n",
        "# Verificar se boto3 esta disponivel (para upload ao R2)\n",
        "try:\n",
        "    import boto3\n",
        "    BOTO3_OK = True\n",
        "    print(\"boto3: disponivel\")\n",
        "except ImportError:\n",
        "    BOTO3_OK = False\n",
        "    print(\"boto3: NAO disponivel (upload ao R2 sera simulado)\")\n",
        "\n",
        "CLIMADA_OK = True\n",
        "print(\"\\nOK - Ambiente verificado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nb05_bloco02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a780255-975c-4e65-935a-e69cd45fcda7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Endpoint: https://fcbf44d6ba0cfc8e007fb276e5582cc2.r2.cloudflarestorage.com\n",
            "R2 Bucket: climarisk-og\n",
            "R2 Credentials: NAO CONFIGURADAS (modo local)\n",
            "Output dir: ./outputs\n",
            "\n",
            "OK - Imports e configuracao carregados\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 2: IMPORTS E CONFIGURACAO\n",
        "# =============================================================================\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# CLIMADA core\n",
        "from climada.hazard import Hazard, Centroids\n",
        "from climada.entity import Exposures, ImpactFuncSet, ImpactFunc\n",
        "from climada.engine import ImpactCalc\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# CLIMADA petals -- funcao de dano JRC para inundacao\n",
        "from climada_petals.entity.impact_funcs.river_flood import (\n",
        "    ImpfRiverFlood, flood_imp_func_set\n",
        ")\n",
        "\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURACAO DO PIPELINE\n",
        "# =============================================================================\n",
        "# Em producao, estas variaveis vem de environment variables do Railway.\n",
        "# No Colab, usamos valores padrao.\n",
        "R2_ENDPOINT = os.environ.get(\n",
        "    'R2_ENDPOINT',\n",
        "    'https://fcbf44d6ba0cfc8e007fb276e5582cc2.r2.cloudflarestorage.com'\n",
        ")\n",
        "R2_BUCKET = os.environ.get('S3_BUCKET_NAME', 'climarisk-og')\n",
        "R2_ACCESS_KEY = os.environ.get('R2_ACCESS_KEY_ID', '')\n",
        "R2_SECRET_KEY = os.environ.get('R2_SECRET_ACCESS_KEY', '')\n",
        "OUTPUT_DIR = os.environ.get('OUTPUT_DIR', './outputs')\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"R2 Endpoint: {R2_ENDPOINT}\")\n",
        "print(f\"R2 Bucket: {R2_BUCKET}\")\n",
        "print(f\"R2 Credentials: {'CONFIGURADAS' if R2_ACCESS_KEY else 'NAO CONFIGURADAS (modo local)'}\")\n",
        "print(f\"Output dir: {OUTPUT_DIR}\")\n",
        "print(\"\\nOK - Imports e configuracao carregados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nb05_bloco03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a6317e-81aa-43de-b08d-f87506bbd8bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ativos registrados: 1\n",
            "  - REDUC - Refinaria Duque de Caxias (-22.53, -43.28) | USD 5,000,000,000\n",
            "    Hazards: ['RF', 'HW']\n",
            "\n",
            "Cenarios SSP: ['SSP2-4.5', 'SSP5-8.5']\n",
            "Horizontes: ['2030', '2050', '2100']\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 3: REGISTRO DE ATIVOS\n",
        "# =============================================================================\n",
        "# Em producao, esta lista vira do banco de dados ou de um JSON de configuracao.\n",
        "# Para TRL5, usamos apenas a REDUC como ativo de referencia.\n",
        "\n",
        "ASSETS = [\n",
        "    {\n",
        "        'name': 'REDUC - Refinaria Duque de Caxias',\n",
        "        'short_name': 'REDUC',\n",
        "        'lat': -22.53,\n",
        "        'lon': -43.28,\n",
        "        'value_usd': 5_000_000_000,\n",
        "        'bbox': {\n",
        "            'lat_min': -23.0, 'lat_max': -22.0,\n",
        "            'lon_min': -43.8, 'lon_max': -42.8\n",
        "        },\n",
        "        'hazards': ['RF', 'HW'],\n",
        "    },\n",
        "]\n",
        "\n",
        "# Cenarios SSP para projecoes futuras\n",
        "SSP_SCENARIOS = {\n",
        "    'SSP2-4.5': {\n",
        "        'description': 'Moderado -- desenvolvimento sustentavel parcial',\n",
        "        'flood_factors': {'2030': 1.05, '2050': 1.12, '2100': 1.25},\n",
        "        'heat_factors':  {'2030': 0.5,  '2050': 1.2,  '2100': 1.8},\n",
        "    },\n",
        "    'SSP5-8.5': {\n",
        "        'description': 'Extremo -- combustiveis fosseis intensivos',\n",
        "        'flood_factors': {'2030': 1.08, '2050': 1.22, '2100': 1.55},\n",
        "        'heat_factors':  {'2030': 0.7,  '2050': 1.8,  '2100': 3.5},\n",
        "    },\n",
        "}\n",
        "\n",
        "HORIZONS = ['2030', '2050', '2100']\n",
        "\n",
        "print(f\"Ativos registrados: {len(ASSETS)}\")\n",
        "for a in ASSETS:\n",
        "    print(f\"  - {a['name']} ({a['lat']}, {a['lon']}) | USD {a['value_usd']:,.0f}\")\n",
        "    print(f\"    Hazards: {a['hazards']}\")\n",
        "\n",
        "print(f\"\\nCenarios SSP: {list(SSP_SCENARIOS.keys())}\")\n",
        "print(f\"Horizontes: {HORIZONS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nb05_bloco04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afc4027-87e3-4680-b107-7fbc841fa2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK - Funcoes auxiliares definidas\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 4: FUNCOES AUXILIARES DO PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def build_centroids(bbox, n_lat=20, n_lon=20):\n",
        "    \"\"\"Constroi grade de centroids a partir de bounding box.\"\"\"\n",
        "    lats = np.linspace(bbox['lat_min'], bbox['lat_max'], n_lat)\n",
        "    lons = np.linspace(bbox['lon_min'], bbox['lon_max'], n_lon)\n",
        "    lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
        "    return Centroids(\n",
        "        lat=lat_grid.flatten(),\n",
        "        lon=lon_grid.flatten(),\n",
        "        crs='EPSG:4326'\n",
        "    )\n",
        "\n",
        "\n",
        "def build_exposure(asset, hazard_types):\n",
        "    \"\"\"Constroi Exposure multi-hazard para um ativo.\"\"\"\n",
        "    # Carregar IDs de impact functions\n",
        "    impf_set_jrc = flood_imp_func_set()\n",
        "    RF_SA_ID = None\n",
        "    for func_id in impf_set_jrc.get_ids().get('RF', []):\n",
        "        func = impf_set_jrc.get_func(haz_type='RF', fun_id=func_id)\n",
        "        if isinstance(func, list):\n",
        "            func = func[0]\n",
        "        if 'South America' in func.name or 'SouthAmerica' in func.name:\n",
        "            RF_SA_ID = func_id\n",
        "            break\n",
        "    if RF_SA_ID is None:\n",
        "        RF_SA_ID = 6\n",
        "\n",
        "    HW_ID = 1\n",
        "\n",
        "    data = {\n",
        "        'value': [asset['value_usd']],\n",
        "        'latitude': [asset['lat']],\n",
        "        'longitude': [asset['lon']],\n",
        "        'asset_name': [asset['name']],\n",
        "    }\n",
        "    if 'RF' in hazard_types:\n",
        "        data['impf_RF'] = [RF_SA_ID]\n",
        "    if 'HW' in hazard_types:\n",
        "        data['impf_HW'] = [HW_ID]\n",
        "\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        data,\n",
        "        geometry=[Point(asset['lon'], asset['lat'])],\n",
        "        crs='EPSG:4326'\n",
        "    )\n",
        "    exp = Exposures(gdf)\n",
        "    exp.value_unit = 'USD'\n",
        "    exp.check()\n",
        "    return exp, RF_SA_ID, HW_ID\n",
        "\n",
        "\n",
        "def build_flood_hazard(centroids, asset_lat, asset_lon, scale_factor=1.0):\n",
        "    \"\"\"Constroi hazard de inundacao (identico ao NB01).\n",
        "    scale_factor: multiplicador para projecoes futuras.\n",
        "    \"\"\"\n",
        "    events = [\n",
        "        {'name': 'flood_rp5',   'rp': 5,   'max_depth': 0.5,  'year': 2020},\n",
        "        {'name': 'flood_rp10',  'rp': 10,  'max_depth': 1.0,  'year': 2015},\n",
        "        {'name': 'flood_rp25',  'rp': 25,  'max_depth': 1.8,  'year': 2010},\n",
        "        {'name': 'flood_rp50',  'rp': 50,  'max_depth': 2.5,  'year': 2000},\n",
        "        {'name': 'flood_rp100', 'rp': 100, 'max_depth': 3.5,  'year': 1988},\n",
        "        {'name': 'flood_rp250', 'rp': 250, 'max_depth': 4.5,  'year': 1966},\n",
        "    ]\n",
        "    n_events = len(events)\n",
        "    n_centroids = centroids.size\n",
        "\n",
        "    intensity = np.zeros((n_events, n_centroids))\n",
        "    fraction = np.zeros((n_events, n_centroids))\n",
        "\n",
        "    for i, evt in enumerate(events):\n",
        "        dist = np.sqrt(\n",
        "            (centroids.lat - asset_lat)**2 +\n",
        "            (centroids.lon - asset_lon)**2\n",
        "        )\n",
        "        max_radius = 0.3\n",
        "        depth = evt['max_depth'] * scale_factor * np.maximum(0, 1 - dist / max_radius)\n",
        "        np.random.seed(42 + i)\n",
        "        noise = np.random.normal(1.0, 0.2, n_centroids)\n",
        "        noise = np.clip(noise, 0.5, 1.5)\n",
        "        depth = depth * noise\n",
        "        depth = np.maximum(0, depth)\n",
        "        intensity[i, :] = depth\n",
        "        fraction[i, :] = np.where(\n",
        "            depth > 0.01,\n",
        "            np.minimum(1.0, depth / (evt['max_depth'] * scale_factor)),\n",
        "            0.0\n",
        "        )\n",
        "\n",
        "    haz = Hazard(\n",
        "        haz_type='RF',\n",
        "        centroids=centroids,\n",
        "        event_id=np.arange(1, n_events + 1),\n",
        "        event_name=[e['name'] for e in events],\n",
        "        date=np.array([datetime(e['year'], 1, 15).toordinal() for e in events]),\n",
        "        frequency=np.array([1.0 / e['rp'] for e in events]),\n",
        "        frequency_unit='1/year',\n",
        "        intensity=csr_matrix(intensity),\n",
        "        fraction=csr_matrix(fraction),\n",
        "        units='m',\n",
        "    )\n",
        "    haz.check()\n",
        "    return haz, events\n",
        "\n",
        "\n",
        "def build_heat_hazard(centroids, asset_lat, asset_lon, delta_offset=0.0):\n",
        "    \"\"\"Constroi hazard de ondas de calor (identico ao NB02).\n",
        "    delta_offset: acrescimo em deg_C para projecoes futuras.\n",
        "    \"\"\"\n",
        "    HEAT_THRESHOLD_C = 40.0\n",
        "    events = [\n",
        "        {'name': 'heatwave_rp2',   'rp': 2,   'delta_above': 2.0,  'year': 2023},\n",
        "        {'name': 'heatwave_rp5',   'rp': 5,   'delta_above': 3.5,  'year': 2020},\n",
        "        {'name': 'heatwave_rp10',  'rp': 10,  'delta_above': 5.0,  'year': 2016},\n",
        "        {'name': 'heatwave_rp25',  'rp': 25,  'delta_above': 6.5,  'year': 2010},\n",
        "        {'name': 'heatwave_rp50',  'rp': 50,  'delta_above': 8.0,  'year': 1998},\n",
        "        {'name': 'heatwave_rp100', 'rp': 100, 'delta_above': 10.0, 'year': 1984},\n",
        "    ]\n",
        "    n_events = len(events)\n",
        "    n_centroids = centroids.size\n",
        "\n",
        "    intensity = np.zeros((n_events, n_centroids))\n",
        "    fraction = np.zeros((n_events, n_centroids))\n",
        "\n",
        "    for i, evt in enumerate(events):\n",
        "        np.random.seed(100 + i)\n",
        "        base_temp = evt['delta_above'] + delta_offset\n",
        "        spatial_var = np.random.normal(0, 0.5, n_centroids)\n",
        "        dist = np.sqrt(\n",
        "            (centroids.lat - asset_lat)**2 +\n",
        "            (centroids.lon - asset_lon)**2\n",
        "        )\n",
        "        urban_heat = np.maximum(0, 0.5 * (1 - dist / 0.3))\n",
        "        temp_field = base_temp + spatial_var + urban_heat\n",
        "        temp_field = np.maximum(0, temp_field)\n",
        "        intensity[i, :] = temp_field\n",
        "        fraction[i, :] = np.where(temp_field > 0.1, 1.0, 0.0)\n",
        "\n",
        "    haz = Hazard(\n",
        "        haz_type='HW',\n",
        "        centroids=centroids,\n",
        "        event_id=np.arange(1, n_events + 1),\n",
        "        event_name=[e['name'] for e in events],\n",
        "        date=np.array([datetime(e['year'], 7, 15).toordinal() for e in events]),\n",
        "        frequency=np.array([1.0 / e['rp'] for e in events]),\n",
        "        frequency_unit='1/year',\n",
        "        intensity=csr_matrix(intensity),\n",
        "        fraction=csr_matrix(fraction),\n",
        "        units='deg_C above threshold',\n",
        "    )\n",
        "    haz.check()\n",
        "    return haz, events, HEAT_THRESHOLD_C\n",
        "\n",
        "\n",
        "def build_impact_func_set(rf_sa_id, hw_id):\n",
        "    \"\"\"Constroi ImpactFuncSet unificado (identico ao NB03).\"\"\"\n",
        "    # Inundacao via climada_petals\n",
        "    impf_set_jrc = flood_imp_func_set()\n",
        "    impf_flood = impf_set_jrc.get_func(haz_type='RF', fun_id=rf_sa_id)\n",
        "    if isinstance(impf_flood, list):\n",
        "        impf_flood = impf_flood[0]\n",
        "\n",
        "    # Calor customizada (identica ao NB02)\n",
        "    impf_heat = ImpactFunc(\n",
        "        id=hw_id,\n",
        "        haz_type='HW',\n",
        "        name='Heat Wave -- Industrial Facility (Refinery)',\n",
        "        intensity_unit='deg_C above threshold',\n",
        "        intensity=np.array([0.0, 1.0, 2.0, 3.0, 5.0, 7.0, 10.0, 15.0]),\n",
        "        mdd=np.array(       [0.0, 0.02, 0.05, 0.10, 0.25, 0.45, 0.70, 0.95]),\n",
        "        paa=np.array(       [0.0, 0.10, 0.20, 0.35, 0.55, 0.75, 0.90, 1.00]),\n",
        "    )\n",
        "\n",
        "    impf_set = ImpactFuncSet([impf_flood, impf_heat])\n",
        "    impf_set.check()\n",
        "    return impf_set, impf_flood, impf_heat\n",
        "\n",
        "\n",
        "print(\"OK - Funcoes auxiliares definidas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nb05_bloco05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918a6349-c7e6-4e68-ebf0-c87226146013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK - Funcoes de calculo definidas\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 5: FUNCAO DE CALCULO DE IMPACTO POR HAZARD\n",
        "# =============================================================================\n",
        "\n",
        "def compute_impact_single(exp, impf_set, haz, events, hazard_type):\n",
        "    \"\"\"Calcula impacto para um hazard e retorna dicionario de resultados.\"\"\"\n",
        "    imp = ImpactCalc(exp, impf_set, haz).impact(save_mat=True)\n",
        "    eai = float(imp.aai_agg)\n",
        "    value = float(exp.gdf['value'].sum())\n",
        "\n",
        "    result = {\n",
        "        'eai_usd': eai,\n",
        "        'eai_ratio_pct': float((eai / value) * 100) if value > 0 else 0.0,\n",
        "        'impact_by_return_period': {\n",
        "            str(evt['rp']): float(imp.at_event[i])\n",
        "            for i, evt in enumerate(events)\n",
        "        },\n",
        "    }\n",
        "    return result, imp\n",
        "\n",
        "\n",
        "def run_baseline(asset, centroids, exp, impf_set, rf_sa_id):\n",
        "    \"\"\"Executa analise baseline (NB01 + NB02 + NB03 combinados).\"\"\"\n",
        "    results = {\n",
        "        'scenario': 'baseline',\n",
        "        'horizon': 'historical',\n",
        "        'hazards': {},\n",
        "    }\n",
        "\n",
        "    total_eai = 0.0\n",
        "\n",
        "    if 'RF' in asset['hazards']:\n",
        "        haz_flood, events_rf = build_flood_hazard(\n",
        "            centroids, asset['lat'], asset['lon']\n",
        "        )\n",
        "        res_rf, _ = compute_impact_single(\n",
        "            exp, impf_set, haz_flood, events_rf, 'RF'\n",
        "        )\n",
        "        impf_set_jrc = flood_imp_func_set()\n",
        "        impf_flood = impf_set_jrc.get_func(haz_type='RF', fun_id=rf_sa_id)\n",
        "        if isinstance(impf_flood, list):\n",
        "            impf_flood = impf_flood[0]\n",
        "        results['hazards']['RF'] = {\n",
        "            'type': 'RF',\n",
        "            'type_name': 'River Flood',\n",
        "            'n_events': len(events_rf),\n",
        "            'return_periods': [e['rp'] for e in events_rf],\n",
        "            'intensity_unit': 'm',\n",
        "            'max_intensity': float(haz_flood.intensity.max()),\n",
        "            'impact_function': {\n",
        "                'name': impf_flood.name,\n",
        "                'id': int(impf_flood.id) if isinstance(impf_flood.id, (int, np.integer)) else str(impf_flood.id),\n",
        "                'source': 'Huizinga et al. (2017), doi: 10.2760/16510',\n",
        "                'loaded_via': 'climada_petals.entity.impact_funcs.river_flood.flood_imp_func_set()',\n",
        "                'type': 'structural_damage',\n",
        "            },\n",
        "            'results': res_rf,\n",
        "        }\n",
        "        total_eai += res_rf['eai_usd']\n",
        "\n",
        "    if 'HW' in asset['hazards']:\n",
        "        haz_heat, events_hw, threshold = build_heat_hazard(\n",
        "            centroids, asset['lat'], asset['lon']\n",
        "        )\n",
        "        res_hw, _ = compute_impact_single(\n",
        "            exp, impf_set, haz_heat, events_hw, 'HW'\n",
        "        )\n",
        "        results['hazards']['HW'] = {\n",
        "            'type': 'HW',\n",
        "            'type_name': 'Heat Wave',\n",
        "            'n_events': len(events_hw),\n",
        "            'return_periods': [e['rp'] for e in events_hw],\n",
        "            'intensity_unit': 'deg_C above threshold',\n",
        "            'threshold_c': threshold,\n",
        "            'max_intensity': float(haz_heat.intensity.max()),\n",
        "            'impact_function': {\n",
        "                'name': 'Heat Wave -- Industrial Facility (Refinery)',\n",
        "                'source': 'Custom -- ECA/McKinsey (2009), Kjellstrom et al. (2016), ILO (2019)',\n",
        "                'type': 'operational_loss',\n",
        "            },\n",
        "            'results': res_hw,\n",
        "        }\n",
        "        total_eai += res_hw['eai_usd']\n",
        "\n",
        "    results['aggregated'] = {\n",
        "        'eai_total_usd': total_eai,\n",
        "        'eai_total_ratio_pct': float((total_eai / asset['value_usd']) * 100),\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_ssp_projection(asset, centroids, exp, impf_set, scenario_name, scenario_cfg, horizon):\n",
        "    \"\"\"Executa analise sob cenario SSP para um horizonte.\"\"\"\n",
        "    results = {\n",
        "        'scenario': scenario_name,\n",
        "        'horizon': horizon,\n",
        "        'hazards': {},\n",
        "    }\n",
        "\n",
        "    total_eai = 0.0\n",
        "\n",
        "    if 'RF' in asset['hazards']:\n",
        "        sf = scenario_cfg['flood_factors'][horizon]\n",
        "        haz_flood, events_rf = build_flood_hazard(\n",
        "            centroids, asset['lat'], asset['lon'], scale_factor=sf\n",
        "        )\n",
        "        res_rf, _ = compute_impact_single(\n",
        "            exp, impf_set, haz_flood, events_rf, 'RF'\n",
        "        )\n",
        "        results['hazards']['RF'] = {\n",
        "            'type': 'RF',\n",
        "            'type_name': 'River Flood',\n",
        "            'scale_factor': sf,\n",
        "            'results': res_rf,\n",
        "        }\n",
        "        total_eai += res_rf['eai_usd']\n",
        "\n",
        "    if 'HW' in asset['hazards']:\n",
        "        delta = scenario_cfg['heat_factors'][horizon]\n",
        "        haz_heat, events_hw, threshold = build_heat_hazard(\n",
        "            centroids, asset['lat'], asset['lon'], delta_offset=delta\n",
        "        )\n",
        "        res_hw, _ = compute_impact_single(\n",
        "            exp, impf_set, haz_heat, events_hw, 'HW'\n",
        "        )\n",
        "        results['hazards']['HW'] = {\n",
        "            'type': 'HW',\n",
        "            'type_name': 'Heat Wave',\n",
        "            'delta_offset_c': delta,\n",
        "            'results': res_hw,\n",
        "        }\n",
        "        total_eai += res_hw['eai_usd']\n",
        "\n",
        "    results['aggregated'] = {\n",
        "        'eai_total_usd': total_eai,\n",
        "        'eai_total_ratio_pct': float((total_eai / asset['value_usd']) * 100),\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"OK - Funcoes de calculo definidas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nb05_bloco06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105af9d7-660a-497d-915c-4734f862f31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK - Funcao de upload definida\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 6: FUNCAO DE UPLOAD AO R2\n",
        "# =============================================================================\n",
        "\n",
        "def upload_to_r2(filepath, r2_key):\n",
        "    \"\"\"Faz upload de um arquivo local para o Cloudflare R2.\n",
        "    Retorna True se sucesso, False se credenciais nao configuradas.\n",
        "    \"\"\"\n",
        "    if not R2_ACCESS_KEY or not BOTO3_OK:\n",
        "        print(f\"  [SIMULADO] Upload: {filepath} -> s3://{R2_BUCKET}/{r2_key}\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        s3 = boto3.client(\n",
        "            's3',\n",
        "            endpoint_url=R2_ENDPOINT,\n",
        "            aws_access_key_id=R2_ACCESS_KEY,\n",
        "            aws_secret_access_key=R2_SECRET_KEY,\n",
        "            region_name='auto',\n",
        "        )\n",
        "        s3.upload_file(filepath, R2_BUCKET, r2_key)\n",
        "        print(f\"  [OK] Upload: {filepath} -> s3://{R2_BUCKET}/{r2_key}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"  [ERRO] Upload falhou: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "print(\"OK - Funcao de upload definida\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nb05_bloco07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6723f3e9-9afb-4d67-86a8-fa477a70ccd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "  CLIMARISK-OG | BATCH PIPELINE | INICIO\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "  ATIVO: REDUC - Refinaria Duque de Caxias\n",
            "============================================================\n",
            "  Centroids: 400\n",
            "  Exposure: USD 5,000,000,000\n",
            "  Impact Functions: RF(id=61), HW(id=1)\n",
            "\n",
            "  --- Baseline ---\n",
            "  EAI Total: USD 1,345,325,260 (26.91%)\n",
            "    RF: USD 938,842,272\n",
            "    HW: USD 406,482,988\n",
            "\n",
            "  --- SSP2-4.5 | 2030 ---\n",
            "  EAI Total: USD 1,501,276,670 (30.03%) | Delta vs baseline: +11.6%\n",
            "\n",
            "  --- SSP2-4.5 | 2050 ---\n",
            "  EAI Total: USD 1,737,748,975 (34.75%) | Delta vs baseline: +29.2%\n",
            "\n",
            "  --- SSP2-4.5 | 2100 ---\n",
            "  EAI Total: USD 1,973,065,719 (39.46%) | Delta vs baseline: +46.7%\n",
            "\n",
            "  --- SSP5-8.5 | 2030 ---\n",
            "  EAI Total: USD 1,573,686,630 (31.47%) | Delta vs baseline: +17.0%\n",
            "\n",
            "  --- SSP5-8.5 | 2050 ---\n",
            "  EAI Total: USD 1,963,159,723 (39.26%) | Delta vs baseline: +45.9%\n",
            "\n",
            "  --- SSP5-8.5 | 2100 ---\n",
            "  EAI Total: USD 2,801,082,961 (56.02%) | Delta vs baseline: +108.2%\n",
            "\n",
            "  JSON salvo: ./outputs/results_pipeline_reduc.json\n",
            "  [SIMULADO] Upload: ./outputs/results_pipeline_reduc.json -> s3://climarisk-og/outputs/reduc/results_pipeline_reduc.json\n",
            "  Tempo: 0.5s\n",
            "\n",
            "======================================================================\n",
            "  PIPELINE CONCLUIDO em 0.5s\n",
            "  Ativos processados: 1\n",
            "  Arquivos gerados: 1\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 7: EXECUCAO DO PIPELINE COMPLETO\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"  CLIMARISK-OG | BATCH PIPELINE | INICIO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "pipeline_start = time.time()\n",
        "pipeline_results = []\n",
        "all_files = []\n",
        "\n",
        "for asset in ASSETS:\n",
        "    asset_start = time.time()\n",
        "    short = asset['short_name']\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  ATIVO: {asset['name']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --- Preparacao ---\n",
        "    centroids = build_centroids(asset['bbox'])\n",
        "    exp, rf_sa_id, hw_id = build_exposure(asset, asset['hazards'])\n",
        "    impf_set, impf_flood, impf_heat = build_impact_func_set(rf_sa_id, hw_id)\n",
        "    print(f\"  Centroids: {centroids.size}\")\n",
        "    print(f\"  Exposure: USD {asset['value_usd']:,.0f}\")\n",
        "    print(f\"  Impact Functions: RF(id={rf_sa_id}), HW(id={hw_id})\")\n",
        "\n",
        "    # --- Baseline ---\n",
        "    print(f\"\\n  --- Baseline ---\")\n",
        "    baseline = run_baseline(asset, centroids, exp, impf_set, rf_sa_id)\n",
        "    eai_b = baseline['aggregated']['eai_total_usd']\n",
        "    ratio_b = baseline['aggregated']['eai_total_ratio_pct']\n",
        "    print(f\"  EAI Total: USD {eai_b:,.0f} ({ratio_b:.2f}%)\")\n",
        "\n",
        "    if 'RF' in baseline['hazards']:\n",
        "        eai_rf = baseline['hazards']['RF']['results']['eai_usd']\n",
        "        print(f\"    RF: USD {eai_rf:,.0f}\")\n",
        "    if 'HW' in baseline['hazards']:\n",
        "        eai_hw = baseline['hazards']['HW']['results']['eai_usd']\n",
        "        print(f\"    HW: USD {eai_hw:,.0f}\")\n",
        "\n",
        "    # --- Projecoes SSP ---\n",
        "    projections = []\n",
        "    for ssp_name, ssp_cfg in SSP_SCENARIOS.items():\n",
        "        for horizon in HORIZONS:\n",
        "            print(f\"\\n  --- {ssp_name} | {horizon} ---\")\n",
        "            proj = run_ssp_projection(\n",
        "                asset, centroids, exp, impf_set,\n",
        "                ssp_name, ssp_cfg, horizon\n",
        "            )\n",
        "            eai_p = proj['aggregated']['eai_total_usd']\n",
        "            ratio_p = proj['aggregated']['eai_total_ratio_pct']\n",
        "            delta_pct = ((eai_p - eai_b) / eai_b * 100) if eai_b > 0 else 0\n",
        "            print(f\"  EAI Total: USD {eai_p:,.0f} ({ratio_p:.2f}%) | Delta vs baseline: {delta_pct:+.1f}%\")\n",
        "            proj['delta_vs_baseline_pct'] = delta_pct\n",
        "            projections.append(proj)\n",
        "\n",
        "    # --- Montar JSON consolidado ---\n",
        "    asset_result = {\n",
        "        'metadata': {\n",
        "            'pipeline': 'nb05_batch_pipeline',\n",
        "            'version': '1.0',\n",
        "            'date': datetime.now().isoformat(),\n",
        "            'climada_version': ver,\n",
        "            'methodology': 'CLIMADA multi-hazard probabilistic impact (H x E x V)',\n",
        "        },\n",
        "        'asset': {\n",
        "            'name': asset['name'],\n",
        "            'short_name': short,\n",
        "            'lat': asset['lat'],\n",
        "            'lon': asset['lon'],\n",
        "            'value_usd': asset['value_usd'],\n",
        "        },\n",
        "        'baseline': baseline,\n",
        "        'projections': projections,\n",
        "        'scenarios_config': {\n",
        "            ssp_name: {\n",
        "                'description': cfg['description'],\n",
        "                'flood_factors': cfg['flood_factors'],\n",
        "                'heat_factors': cfg['heat_factors'],\n",
        "            }\n",
        "            for ssp_name, cfg in SSP_SCENARIOS.items()\n",
        "        },\n",
        "        'limitations': [\n",
        "            'Dados de hazard sinteticos para ambos os riscos',\n",
        "            'Valor de exposicao estimado',\n",
        "            'Funcao de dano de calor customizada (nao calibrada com dados reais)',\n",
        "            'Funcao de dano de inundacao generica (residencial, JRC)',\n",
        "            'Independencia entre hazards assumida (soma simples de EAIs)',\n",
        "            'Fatores de escala SSP baseados em medias globais IPCC AR6',\n",
        "            'Ativo unico (REDUC)',\n",
        "            'Sem modelagem de correlacao entre cenarios',\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    # --- Salvar JSON ---\n",
        "    filename = f\"results_pipeline_{short.lower()}.json\"\n",
        "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
        "    with open(filepath, 'w', encoding='utf-8') as f:\n",
        "        json.dump(asset_result, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"\\n  JSON salvo: {filepath}\")\n",
        "    all_files.append(filepath)\n",
        "\n",
        "    # --- Upload ao R2 ---\n",
        "    r2_key = f\"outputs/{short.lower()}/{filename}\"\n",
        "    upload_to_r2(filepath, r2_key)\n",
        "\n",
        "    asset_elapsed = time.time() - asset_start\n",
        "    print(f\"  Tempo: {asset_elapsed:.1f}s\")\n",
        "    pipeline_results.append(asset_result)\n",
        "\n",
        "pipeline_elapsed = time.time() - pipeline_start\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"  PIPELINE CONCLUIDO em {pipeline_elapsed:.1f}s\")\n",
        "print(f\"  Ativos processados: {len(ASSETS)}\")\n",
        "print(f\"  Arquivos gerados: {len(all_files)}\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nb05_bloco08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b8e374-9049-4a42-bea1-0de9e4644c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  SUMARIO DE RESULTADOS\n",
            "======================================================================\n",
            "\n",
            "  ATIVO: REDUC - Refinaria Duque de Caxias\n",
            "  Valor: USD 5,000,000,000\n",
            "\n",
            "  Cenario              Horizonte    EAI (USD M)     Ratio (%)    Delta (%)   \n",
            "  -----------------------------------------------------------------------\n",
            "  Baseline             historico    1,345.3         26.91        ---         \n",
            "  SSP2-4.5             2030         1,501.3         30.03        +11.6       \n",
            "  SSP2-4.5             2050         1,737.7         34.75        +29.2       \n",
            "  SSP2-4.5             2100         1,973.1         39.46        +46.7       \n",
            "  SSP5-8.5             2030         1,573.7         31.47        +17.0       \n",
            "  SSP5-8.5             2050         1,963.2         39.26        +45.9       \n",
            "  SSP5-8.5             2100         2,801.1         56.02        +108.2      \n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 8: SUMARIO DE RESULTADOS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"  SUMARIO DE RESULTADOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for asset_result in pipeline_results:\n",
        "    asset_name = asset_result['asset']['short_name']\n",
        "    value = asset_result['asset']['value_usd']\n",
        "    bl = asset_result['baseline']\n",
        "\n",
        "    print(f\"\\n  ATIVO: {asset_result['asset']['name']}\")\n",
        "    print(f\"  Valor: USD {value:,.0f}\")\n",
        "    print(f\"\\n  {'Cenario':<20} {'Horizonte':<12} {'EAI (USD M)':<15} {'Ratio (%)':<12} {'Delta (%)':<12}\")\n",
        "    print(f\"  {'-'*71}\")\n",
        "\n",
        "    # Baseline\n",
        "    eai_bl = bl['aggregated']['eai_total_usd']\n",
        "    ratio_bl = bl['aggregated']['eai_total_ratio_pct']\n",
        "    print(f\"  {'Baseline':<20} {'historico':<12} {eai_bl/1e6:<15,.1f} {ratio_bl:<12.2f} {'---':<12}\")\n",
        "\n",
        "    # Projecoes\n",
        "    for proj in asset_result['projections']:\n",
        "        ssp = proj['scenario']\n",
        "        hor = proj['horizon']\n",
        "        eai_p = proj['aggregated']['eai_total_usd']\n",
        "        ratio_p = proj['aggregated']['eai_total_ratio_pct']\n",
        "        delta = proj.get('delta_vs_baseline_pct', 0)\n",
        "        print(f\"  {ssp:<20} {hor:<12} {eai_p/1e6:<15,.1f} {ratio_p:<12.2f} {delta:<+12.1f}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nb05_bloco09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e905bd-1121-4f39-e1bd-e63d62f4bd9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  RESUMO EXECUTIVO -- CLIMARISK-OG | Notebook 05 | Batch Pipeline\n",
            "======================================================================\n",
            "\n",
            "  ATIVO:       REDUC - Refinaria Duque de Caxias\n",
            "  LOCALIZACAO: (-22.53, -43.28)\n",
            "  VALOR:       USD 5 bilhoes\n",
            "\n",
            "  BASELINE:\n",
            "    EAI Total:  USD   1,345,325,260\n",
            "    Ratio:               26.91%\n",
            "\n",
            "  CENARIO MAIS SEVERO (SSP5-8.5 | 2100):\n",
            "    EAI Total:  USD   2,801,082,961\n",
            "    Delta:              +108.2%\n",
            "\n",
            "  CENARIO MAIS BRANDO (SSP2-4.5 | 2030):\n",
            "    EAI Total:  USD   1,501,276,670\n",
            "    Delta:               +11.6%\n",
            "\n",
            "  PIPELINE:\n",
            "    Cenarios processados: 6 (baseline + 6 projecoes)\n",
            "    Tempo total: 0.5s\n",
            "    JSONs gerados: 1\n",
            "    Upload R2: SIMULADO (sem credenciais)\n",
            "\n",
            "  LIMITACOES (TRL5):\n",
            "    1. Dados de hazard sinteticos\n",
            "    2. Valor de exposicao estimado\n",
            "    3. Funcao de dano de calor customizada (nao calibrada)\n",
            "    4. Funcao de dano de inundacao generica residencial (JRC)\n",
            "    5. Independencia entre hazards (soma simples)\n",
            "    6. Fatores de escala SSP baseados em medias globais IPCC AR6\n",
            "    7. Ativo unico (REDUC)\n",
            "\n",
            "======================================================================\n",
            "  FIM DO NOTEBOOK 05 -- Batch Pipeline v1.0\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 9: RESUMO EXECUTIVO\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"  RESUMO EXECUTIVO -- CLIMARISK-OG | Notebook 05 | Batch Pipeline\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for ar in pipeline_results:\n",
        "    bl = ar['baseline']\n",
        "    projs = ar['projections']\n",
        "    worst = max(projs, key=lambda p: p['aggregated']['eai_total_usd'])\n",
        "    best = min(projs, key=lambda p: p['aggregated']['eai_total_usd'])\n",
        "\n",
        "    print(f\"\"\"\n",
        "  ATIVO:       {ar['asset']['name']}\n",
        "  LOCALIZACAO: ({ar['asset']['lat']}, {ar['asset']['lon']})\n",
        "  VALOR:       USD {ar['asset']['value_usd']/1e9:.0f} bilhoes\n",
        "\n",
        "  BASELINE:\n",
        "    EAI Total:  USD {bl['aggregated']['eai_total_usd']:>15,.0f}\n",
        "    Ratio:      {bl['aggregated']['eai_total_ratio_pct']:>14.2f}%\n",
        "\n",
        "  CENARIO MAIS SEVERO ({worst['scenario']} | {worst['horizon']}):\n",
        "    EAI Total:  USD {worst['aggregated']['eai_total_usd']:>15,.0f}\n",
        "    Delta:      {worst.get('delta_vs_baseline_pct', 0):>+14.1f}%\n",
        "\n",
        "  CENARIO MAIS BRANDO ({best['scenario']} | {best['horizon']}):\n",
        "    EAI Total:  USD {best['aggregated']['eai_total_usd']:>15,.0f}\n",
        "    Delta:      {best.get('delta_vs_baseline_pct', 0):>+14.1f}%\n",
        "\n",
        "  PIPELINE:\n",
        "    Cenarios processados: {len(projs)} (baseline + {len(projs)} projecoes)\n",
        "    Tempo total: {pipeline_elapsed:.1f}s\n",
        "    JSONs gerados: {len(all_files)}\n",
        "    Upload R2: {'ATIVO' if R2_ACCESS_KEY else 'SIMULADO (sem credenciais)'}\n",
        "\n",
        "  LIMITACOES (TRL5):\n",
        "    1. Dados de hazard sinteticos\n",
        "    2. Valor de exposicao estimado\n",
        "    3. Funcao de dano de calor customizada (nao calibrada)\n",
        "    4. Funcao de dano de inundacao generica residencial (JRC)\n",
        "    5. Independencia entre hazards (soma simples)\n",
        "    6. Fatores de escala SSP baseados em medias globais IPCC AR6\n",
        "    7. Ativo unico (REDUC)\n",
        "\n",
        "======================================================================\n",
        "  FIM DO NOTEBOOK 05 -- Batch Pipeline v1.0\n",
        "======================================================================\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nb05_bloco10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a889ea2b-4efe-4078-b89a-8a7db1976866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "  PARTE 1: ARTEFATOS GERADOS\n",
            "============================================================\n",
            "  OK ./outputs/results_pipeline_reduc.json (11.4 KB)\n",
            "\n",
            "============================================================\n",
            "  PARTE 2: DIAGNOSTICO DE CONSISTENCIA\n",
            "============================================================\n",
            "  [OK] Pipeline executou: 1 ativos\n",
            "  [OK] Baseline EAI > 0 (REDUC): USD 1,345,325,260\n",
            "  [OK] EAI > 0 (SSP2-4.5 2030): USD 1,501,276,670\n",
            "  [OK] EAI > 0 (SSP2-4.5 2050): USD 1,737,748,975\n",
            "  [OK] EAI > 0 (SSP2-4.5 2100): USD 1,973,065,719\n",
            "  [OK] EAI > 0 (SSP5-8.5 2030): USD 1,573,686,630\n",
            "  [OK] EAI > 0 (SSP5-8.5 2050): USD 1,963,159,723\n",
            "  [OK] EAI > 0 (SSP5-8.5 2100): USD 2,801,082,961\n",
            "  [OK] JSON existe: results_pipeline_reduc.json: \n",
            "  [OK] JSON valido: results_pipeline_reduc.json: \n",
            "  [OK] SSP5-8.5 2100 > Baseline: 2,801,082,961 vs 1,345,325,260\n",
            "\n",
            "  Resultado: 11/11 checks passaram\n",
            "  Notebook pronto para commit no GitHub.\n",
            "\n",
            "Conteudo do JSON (results_pipeline_reduc.json) -- primeiras 80 linhas:\n",
            "{\n",
            "  \"metadata\": {\n",
            "    \"pipeline\": \"nb05_batch_pipeline\",\n",
            "    \"version\": \"1.0\",\n",
            "    \"date\": \"2026-03-01T17:05:06.782756\",\n",
            "    \"climada_version\": \"6.1.0\",\n",
            "    \"methodology\": \"CLIMADA multi-hazard probabilistic impact (H x E x V)\"\n",
            "  },\n",
            "  \"asset\": {\n",
            "    \"name\": \"REDUC - Refinaria Duque de Caxias\",\n",
            "    \"short_name\": \"REDUC\",\n",
            "    \"lat\": -22.53,\n",
            "    \"lon\": -43.28,\n",
            "    \"value_usd\": 5000000000\n",
            "  },\n",
            "  \"baseline\": {\n",
            "    \"scenario\": \"baseline\",\n",
            "    \"horizon\": \"historical\",\n",
            "    \"hazards\": {\n",
            "      \"RF\": {\n",
            "        \"type\": \"RF\",\n",
            "        \"type_name\": \"River Flood\",\n",
            "        \"n_events\": 6,\n",
            "        \"return_periods\": [\n",
            "          5,\n",
            "          10,\n",
            "          25,\n",
            "          50,\n",
            "          100,\n",
            "          250\n",
            "        ],\n",
            "        \"intensity_unit\": \"m\",\n",
            "        \"max_intensity\": 5.233794259460427,\n",
            "        \"impact_function\": {\n",
            "          \"name\": \"Flood SouthAmerica JRC Residential noPAA\",\n",
            "          \"id\": 61,\n",
            "          \"source\": \"Huizinga et al. (2017), doi: 10.2760/16510\",\n",
            "          \"loaded_via\": \"climada_petals.entity.impact_funcs.river_flood.flood_imp_func_set()\",\n",
            "          \"type\": \"structural_damage\"\n",
            "        },\n",
            "        \"results\": {\n",
            "          \"eai_usd\": 938842272.3078985,\n",
            "          \"eai_ratio_pct\": 18.77684544615797,\n",
            "          \"impact_by_return_period\": {\n",
            "            \"5\": 1911036611.6026037,\n",
            "            \"10\": 3212908957.2256956,\n",
            "            \"25\": 2264266405.4856467,\n",
            "            \"50\": 3744818215.664442,\n",
            "            \"100\": 4987703373.209349,\n",
            "            \"250\": 5000000000.0\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      \"HW\": {\n",
            "        \"type\": \"HW\",\n",
            "        \"type_name\": \"Heat Wave\",\n",
            "        \"n_events\": 6,\n",
            "        \"return_periods\": [\n",
            "          2,\n",
            "          5,\n",
            "          10,\n",
            "          25,\n",
            "          50,\n",
            "          100\n",
            "        ],\n",
            "        \"intensity_unit\": \"deg_C above threshold\",\n",
            "        \"threshold_c\": 40.0,\n",
            "        \"max_intensity\": 11.457575062626544,\n",
            "        \"impact_function\": {\n",
            "          \"name\": \"Heat Wave -- Industrial Facility (Refinery)\",\n",
            "          \"source\": \"Custom -- ECA/McKinsey (2009), Kjellstrom et al. (2016), ILO (2019)\",\n",
            "          \"type\": \"operational_loss\"\n",
            "        },\n",
            "        \"results\": {\n",
            "          \"eai_usd\": 406482987.6728766,\n",
            "          \"eai_ratio_pct\": 8.129659753457531,\n",
            "          \"impact_by_return_period\": {\n",
            "            \"2\": 248411897.66550297,\n",
            "            \"5\": 247197611.61359856,\n",
            "            \"10\": 1182538189.1695259,\n",
            "  ... (323 linhas omitidas)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BLOCO 10: DIAGNOSTICO E ARTEFATOS\n",
        "# =============================================================================\n",
        "print(\"=\" * 60)\n",
        "print(\"  PARTE 1: ARTEFATOS GERADOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for fp in all_files:\n",
        "    if os.path.exists(fp):\n",
        "        size = os.path.getsize(fp) / 1024\n",
        "        print(f\"  OK {fp} ({size:.1f} KB)\")\n",
        "    else:\n",
        "        print(f\"  FALTA {fp}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"  PARTE 2: DIAGNOSTICO DE CONSISTENCIA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "checks = []\n",
        "\n",
        "# Check 1: Pipeline gerou resultados\n",
        "ok = len(pipeline_results) > 0\n",
        "checks.append(('Pipeline executou', ok, f'{len(pipeline_results)} ativos'))\n",
        "\n",
        "# Check 2: Baseline EAI > 0\n",
        "for ar in pipeline_results:\n",
        "    ok = ar['baseline']['aggregated']['eai_total_usd'] > 0\n",
        "    checks.append((\n",
        "        f\"Baseline EAI > 0 ({ar['asset']['short_name']})\",\n",
        "        ok,\n",
        "        f\"USD {ar['baseline']['aggregated']['eai_total_usd']:,.0f}\"\n",
        "    ))\n",
        "\n",
        "# Check 3: Todas as projecoes tem EAI > 0\n",
        "for ar in pipeline_results:\n",
        "    for proj in ar['projections']:\n",
        "        ok = proj['aggregated']['eai_total_usd'] > 0\n",
        "        checks.append((\n",
        "            f\"EAI > 0 ({proj['scenario']} {proj['horizon']})\",\n",
        "            ok,\n",
        "            f\"USD {proj['aggregated']['eai_total_usd']:,.0f}\"\n",
        "        ))\n",
        "\n",
        "# Check 4: JSONs existem\n",
        "for fp in all_files:\n",
        "    ok = os.path.exists(fp)\n",
        "    checks.append((f'JSON existe: {os.path.basename(fp)}', ok, ''))\n",
        "\n",
        "# Check 5: JSON e valido\n",
        "for fp in all_files:\n",
        "    try:\n",
        "        with open(fp, 'r') as jf:\n",
        "            json.load(jf)\n",
        "        ok = True\n",
        "    except Exception:\n",
        "        ok = False\n",
        "    checks.append((f'JSON valido: {os.path.basename(fp)}', ok, ''))\n",
        "\n",
        "# Check 6: EAI de projecoes SSP5-8.5 2100 > baseline\n",
        "for ar in pipeline_results:\n",
        "    bl_eai = ar['baseline']['aggregated']['eai_total_usd']\n",
        "    worst = [p for p in ar['projections']\n",
        "             if p['scenario'] == 'SSP5-8.5' and p['horizon'] == '2100']\n",
        "    if worst:\n",
        "        ok = worst[0]['aggregated']['eai_total_usd'] > bl_eai\n",
        "        checks.append((\n",
        "            'SSP5-8.5 2100 > Baseline',\n",
        "            ok,\n",
        "            f\"{worst[0]['aggregated']['eai_total_usd']:,.0f} vs {bl_eai:,.0f}\"\n",
        "        ))\n",
        "\n",
        "for name, passed, detail in checks:\n",
        "    status = 'OK' if passed else 'FALHA'\n",
        "    print(f\"  [{status}] {name}: {detail}\")\n",
        "\n",
        "n_passed = sum(1 for _, p, _ in checks if p)\n",
        "print(f\"\\n  Resultado: {n_passed}/{len(checks)} checks passaram\")\n",
        "\n",
        "if n_passed == len(checks):\n",
        "    print(\"  Notebook pronto para commit no GitHub.\")\n",
        "else:\n",
        "    print(\"  ATENCAO: Verificar checks que falharam antes de commitar.\")\n",
        "\n",
        "# Mostrar conteudo do JSON (primeiro ativo)\n",
        "if all_files:\n",
        "    print(f\"\\nConteudo do JSON ({os.path.basename(all_files[0])}) -- primeiras 80 linhas:\")\n",
        "    with open(all_files[0], 'r') as jf:\n",
        "        content = json.dumps(json.load(jf), indent=2, ensure_ascii=False)\n",
        "    lines = content.split('\\n')\n",
        "    for line in lines[:80]:\n",
        "        print(line)\n",
        "    if len(lines) > 80:\n",
        "        print(f\"  ... ({len(lines) - 80} linhas omitidas)\")"
      ]
    }
  ]
}